# Helpers for simulations

There are two alternatives to consider when gating (classifying) points in a
series of cytograms.

+ The first is to estimate the clusterings to be identical across all time
  points. This is equivalent to collapsing all cytograms into one and clustering
  it.
+ The second alternative is to estimate clusters in each cytogram, then connect
  the cytograms as much as one can, e.g., by finding similar clusters across
  time points and combining them.

We use the flowmeans method
(https://www.bioconductor.org/packages/release/bioc/html/flowMeans.html) to
to cluster the cytograms in this section.

## Two alternative clusterings

We will call the two alternatives `underfit_flowmean()` and `overfit_flowmean()`.

```{r}
#' Pool the entire series of cytograms, fit a flowMeans model, and re-aggregate parameters
#' 
#' @param ylist Data.
#' @param numclust Number of clusters.
#' @return List object with flowtrend model estimates using l=lprob=0 and
#'   extremely large regularization parameters so that all cytograms are the
#'   same across time.
#' @export
underfit_flowmeans <- function(ylist, numclust){

  ## Pool all data
  TT <- length(ylist)
  nt <- sapply(ylist, nrow)
  ylist_pooled <- do.call(rbind, ylist) %>% as_tibble()
  colnames(ylist_pooled) = "Y"

  ## Fit the model
  fmns_pooled <- flowMeans::flowMeans(x = ylist_pooled, NumC = numclust)
  labeled_ylist <- data.frame(Y = ylist_pooled$Y,
                              Cluster = fmns_pooled@Label,
                              Time = rep(1:TT, times = nt))

  ## Separate out list of memberships
  memlist = labeled_ylist %>% group_by(Time) %>% group_split() %>% lapply(function(a)pull(a, Cluster))
  
  ## Format nicer output for objective calculations
  params <- labeled_ylist %>% group_by(Cluster, Time) %>% 
    summarise(mu = mean(Y), prob = n(), sigma = var(Y)) %>% 
    group_by(Time) %>% mutate(prob = prob/sum(prob))
  mu <- matrix(nrow = TT, ncol = numclust)
  sigma <- matrix(nrow = TT, ncol = numclust)
  prob <- matrix(nrow = TT, ncol = numclust)
  
  ## Fill in missing times for some clusters
  for(tt in 1:TT){
    
    params.tt <- params %>% filter(Time == tt)
    for(iclust in 1:numclust){
      
      mu[tt,iclust] <- params.tt$mu[iclust]
      sigma[tt,iclust] <- params.tt$sigma[iclust]
      prob[tt,iclust] <- params.tt$prob[iclust]
      
      if(is.na(mu[tt,iclust])){
        mu[tt,iclust] <- mu[tt-1,iclust]
      }
      if(is.na(sigma[tt,iclust])){
        sigma[tt,iclust] <- sigma[tt-1,iclust]
      }
      if(is.na(prob[tt,iclust])){
        prob[tt,iclust] <- 0
      }
    }
  }
  return(list(labeled_ylist = labeled_ylist,
              memlist = memlist,
              params = params,
              mu = mu,
              prob = prob,
              sigma = sigma,
              numclust = numclust))
}
```



```{r}
#' Pool the entire series of cytograms, fit a GMM model, and re-aggregate parameters.
#' 
#' @param ylist Data.
#' @param numclust Number of clusters.
#' @return
#' 
#' @export
underfit_gmm <- function(ylist, numclust){

  ## ## Tempoerary
  ## isignal = 0
  ## isim = 1
  ## destin = file.path("~/repos/flowtrend/inst/output/1dsim-even/data")
  ## datobj = readRDS(file = file.path(destin, paste0("isignal-", isignal,"-isim-", isim, "-", "datobj.RDS")) )
  ## datobj_new = readRDS(file = file.path(destin, paste0("isignal-", isignal,"-isim-", isim, "-", "datobj-new.RDS")) )
  ## ylist = datobj$ylist_unsorted
  ## numclust = 2
  ## ## end of temporary
  
  ## Pool all data
  TT <- length(ylist)
  nt <- sapply(ylist, nrow)
  ylist_pooled <- do.call(rbind, ylist) %>% as_tibble()
  colnames(ylist_pooled) = "y"

  ## Fit the GMM model
  gmm_pooled <- mclust::Mclust(data = ylist_pooled, G = numclust,
                                modelNames = "V", verbose = FALSE)

  ## Memberships (soft- and hard-clustered)
  hard_mem = gmm_pooled$z  %>% apply(1, which.max)
  soft_mem = gmm_pooled$z  %>%
    apply(1, function(myrow){
      sample(1:2, size = 1, replace = FALSE, prob=myrow)
    })

  ## Put together in a table
  tab <- tibble(y = ylist_pooled$y,
                soft_cluster = factor(soft_mem, levels = c(2,1)),
                hard_cluster = factor(hard_mem, levels = c(2,1)),
                time = rep(1:TT, times = nt)) 
  tab_long = tab %>%  pivot_longer(-c("time", "y"), values_to = "cluster",
                                   names_to = "type")
  ## ## Optional plotting code
  ## ggplot(tab_long) +
  ##   geom_point(aes(x=time, y=y, col = cluster), alpha = .5) +
  ##   facet_grid(cluster~type)

  ## ## We need this to return the same mu, prob, and sigma as before
  ## mu = obj_flowtrend$mn
  ## prob = obj_flowtrend$prob
  ## sigma = obj_flowtrend$sigma

  ## That's it! Return the results
  ## param_mat = matrix(NA, nrow = TT, ncol = 6)
  ## colnames(param_mat) = c("time", "mn1", "mn2", "prob1", "prob2", "sd1", "sd2")
  ## param_mat$time = 1:TT
  param_mat = tibble(time=1:TT,
                     mn1 = gmm_pooled$parameters$mean[1],
         mn2 = gmm_pooled$parameters$mean[2],
         sd1 = gmm_pooled$parameters$variance$sigmasq[1],
         sd2 = gmm_pooled$parameters$variance$sigmasq[2],
         prob1 = gmm_pooled$parameters$pro[1],
         prob2 = gmm_pooled$parameters$pro[2])
  mu = param_mat[,c("mn1", "mn2")] %>% as.matrix()
  prob = param_mat[,c("prob1", "prob2")] %>% as.matrix()
  sigma = param_mat[,c("sd1", "sd2")] %>% as.matrix()
  
  ## Soft membership
  memlist = tab_long %>% subset(type == "soft_cluster") %>% group_by(time) %>% 
    group_split() %>% lapply(function(a)pull(a, cluster))

  ## Responsibilities
  soft_mem = gmm_pooled$z %>% as_tibble()
  colnames(soft_mem) = c("clust1", "clust2")
  resp_list = soft_mem %>% add_column( time = rep(1:TT, times = nt))  %>% group_by(time) %>% group_split() %>%
    lapply(select, c("clust1", "clust2")) %>% lapply(as.matrix)

  ## List of sigmas
  TT = nrow(sigma)
  sigma_list = lapply(1:TT, function(tt){
    one_row = sigma[tt,] %>% as.numeric()
    one_sigma = array(NA, dim = c(2,1,1))
    one_sigma[,1,1] = one_row
    return(one_sigma)
  })

  return(list(tab_long = tab_long,
              param_mat = param_mat,
              mu = mu,
              prob = prob,
              sigma = sigma,
              sigma_list = sigma_list,
              memlist = memlist,
              resp_list = resp_list,
              numclust = numclust))
}
```



Here is a plotter function.

```{r}
#' Plotter for underfit and overfit flowmeans.
#' @param ylist Data
#' @param countslist Optional: counts for each ylist
#' @param obj Output from \code{underfit_flowmeans()}
#' @param bin Whether data is binned.
#' @return ggplot object
#' @export
plot_1d_flowmeans <- function(obj, ylist, countslist=NULL, bin = FALSE){

  ## Make plot of only data
  gg = plot_1d(ylist = ylist, countslist = countslist, bin = bin)

  my_wrangle <- function(a, values_to){
    a %>% as_tibble() %>% setNames(c("1", "2", "3")) %>%
      mutate(time=row_number()) %>%
      pivot_longer(-time, names_to = "cluster", values_to = values_to)
  }

  numclust = obj$numclust
  mn_long = obj$mu %>% my_wrangle("mean")
  prob_long = obj$prob %>% my_wrangle("prob")
  ## prob_long = probmat %>% pivot_longer(-time, names_to = "cluster", values_to = "prob")
  est_long = full_join(mn_long, prob_long, by = c("time","cluster"))
  gg = gg + geom_path(aes(x = time, y = mean, linewidth = prob, group = cluster, color = cluster),
                        data = est_long,
                        lineend = "round", linejoin="mitre")+
    scale_linewidth(range = c(0,3), limits = c(0,1))
  
  ## Add the estimated 95% probability regions for data.
  ## stdev = obj$sigma %>% .[,,1] %>% sqrt()
  stdev_long =
    obj$sigma %>% sqrt() %>% my_wrangle("stdev")
  band_long =
    full_join(mn_long, stdev_long, by = c("time", "cluster"))  %>%
    mutate(upper = mean + 1.96 * stdev)  %>% 
    mutate(lower = mean - 1.96 * stdev)
  gg = gg +
    geom_line(aes(x = time, y = upper, group = cluster, color = cluster),
              data = band_long, size = rel(.7), alpha = .5) +
    geom_line(aes(x = time, y = lower, group = cluster, color = cluster),
              data = band_long, size = rel(.7), alpha = .5) +
    guides(size = "none") # To turn off line size from legend
  return(gg)
}
```

Here's a helper to reorder the clusters of the output created using
`underfit_flowmeans()` or `overfit_flowmeans()`.

```{r}
#' Reordering function
reorder_flowmeans <- function(obj, new_order){

  ## Setup
  numclust = max(new_order)

  ## Reorder everything
  obj$prob = obj$prob[,new_order]
  obj$mu = obj$mu[,new_order]
  obj$sigma = obj$sigma[,new_order]
  obj$memlist =  lapply(obj$memlist, function(a){
    a_copy = a
    for(iclust in 1:numclust){
      a_copy[which(a == iclust)] = new_order[iclust]
    }
    return(a_copy)
  })

  ## Reorder the responsibilities
  obj$resp_list =  lapply(obj$resp_list, function(oneresp){
    return(oneresp[,new_order])
  })

  return(obj)
}
```


Next, coding `overfit_flowmeans()`:

```{r}
#' Apply flowmeans sequentially and then cluster match
#' 
#' @param ylist Data.
#' @param numclust Number of clusters.
#' @return 
#' @export
overfit_flowmeans <- function(ylist, numclust, verbose = FALSE){
  
  fmns_obj <- lapply(ylist, FUN = flowmeans_each, numclust = numclust)
  hybrid_out <- match_clusters(fmns_obj)
  return(hybrid_out) 
}
```


We're going to be using gmm instead of flowmeans now.



```{r,}
#' Pool the entire series of cytograms, fit a GMM model, and re-aggregate parameters.
#' 
#' @param ylist Data.
#' @param numclust Number of clusters (only works for 2).
#' @return 
#' @export
overfit_gmm <- function(ylist, numclust = 2, reorder = TRUE){ 

  ## Basic checks
  stopifnot(numclust == 2)

  ## Estimate individual GMM models
  gmm_list <- lapply(ylist, gmm_each, numclust = numclust)

  ## Reorder the cluster memberships sequentially
  if(reorder){
    gmm_list = match_clusters_gmm(gmm_list, numclust = 2)
  }

  ## Obtain the resulting data in long format
  tab_list <- lapply(gmm_list, function(a) a$tab)
  TT = length(ylist)
  names(tab_list) = 1:TT
  tab_long = tab_list %>% bind_rows(.id = "time") %>%
    pivot_longer(-c("time", "y"), values_to = "cluster",
                                   names_to = "type")
  memlist = tab_long %>% subset(type == "soft_cluster") %>% group_by(time) %>%
    group_split() %>% lapply(function(a)pull(a, cluster))

  ## ## temporary: make a plot
  ## ggplot(tab_long) +
  ##   geom_point(aes(x=time, y=y, col = cluster), alpha = .5) +
  ##   facet_grid(cluster~type)

  ## Get the Gaussian distribution parameters
  param_list <- lapply(gmm_list, function(a) a$param)
  param_mat = param_list %>% bind_rows(.id = "time")
  mu = param_mat[,c("mn1", "mn2")] %>% as.matrix()
  prob = param_mat[,c("prob1", "prob2")] %>% as.matrix()
  sigma = param_mat[,c("sd1", "sd2")] %>% .^2 %>% as.matrix()

  ## Responsibilities
  resp_list = gmm_list %>% lapply(function(a) a$resp)

  ## Make a list of each time points' sigmas
  TT = nrow(sigma)
  sigma_list = lapply(1:TT, function(tt){
    one_row = sigma[tt,] %>% as.numeric()
    one_sigma = array(NA, dim = c(2,1,1))
    one_sigma[,1,1] = one_row
    return(one_sigma)
  })

  return(list(tab_long = tab_long,
              param_mat = param_mat,
              mu = mu,
              prob = prob,
              sigma = sigma,
              sigma_list = sigma_list,
              resp_list = resp_list,
              numclust = numclust))
}

##' Sequentially permute a time series of GMMs.
##'
##' @param gmm_list Output of an lapply of gmm_each over ylist.
##' @param numclust Number of clusters.
##'
##' @return Same format as |gmm_list|
match_clusters_gmm <- function(gmm_list, numclust = 2){

  ## Initialize some objects
  TT <- length(gmm_list)
  
  ## Helper to permute one GMM
  my_reorder <- function(one_gmm, new_order){
    one_gmm_reordered = one_gmm
    one_gmm_reordered$tab = one_gmm_reordered$tab %>%
      mutate(hard_cluster = hard_cluster %>%
               plyr::revalue(replace=c("1"=new_order[1],"2"=new_order[2]))) %>%
      mutate(soft_cluster = soft_cluster %>%
               plyr::revalue(replace=c("1"=new_order[1],"2"=new_order[2])))

    ## reorder the parameters
    param = one_gmm$param
    new_mns = param[,c("mn1", "mn2")][new_order] %>% as.numeric()
    new_sds = param[,c("sd1", "sd2")][new_order] %>% as.numeric()
    new_probs = param[,c("prob1", "prob2")][new_order] %>% as.numeric()
    one_gmm_reordered$param <- data.frame(mn1 = new_mns[1], mn2 = new_mns[2],
                                          sd1 = new_sds[1], sd2 = new_sds[2],
                                          prob1 = new_probs[1], prob2 = new_probs[2])
    ## if(all(new_order == 2:1)) browser()

    ## reorder the responsibilities
    one_gmm_reordered$resp = one_gmm$resp[,new_order]
    return(one_gmm_reordered)
  }
  
  ## Fill in the rest of the rows by sequentially matching clusters from t-1 to
  ## t, using the Hungarian Algorithm
  new_orders = matrix(NA, ncol = 2, nrow = TT)
  new_orders[1,] = c(1, 2)
  gmm_list_copy = gmm_list
  for(tt in 2:TT){

    ## Find order
    param1 = gmm_list_copy[[tt-1]] %>% .$param
    param2 = gmm_list[[tt]] %>% .$param
    klmat <- symmetric_kl_between_gaussians(param1 = param1, param2 = param2)
    new_order <- RcppHungarian::HungarianSolver(klmat) %>%
      .$pairs %>% data.frame() %>% arrange(.[,2]) %>% .[,1]
    new_orders[tt,] = new_order

    ## Perform the reordering
    gmm_list_copy[[tt]] <- my_reorder(gmm_list[[tt]], new_order)
  }
  return(gmm_list_copy)
}

##' Between two sets of Gaussian mean/sd parameters, what is the symmetric KL
##' distance.
##' @param param1 list of mn1, mn2, sd1, sd2
##' @param param2 another such list.
##'
##' @return (numclust x numclust) distance matrix.
symmetric_kl_between_gaussians <- function(param1, param2, numclust = 2){

  ## First model's parameters
  mn_model1 = c(param1$mn1, param1$mn2)
  sd_model1 = c(param1$sd1, param1$sd2)

  ## Second model's parameters
  mn_model2 = c(param2$mn1, param2$mn2)
  sd_model2 = c(param2$sd1, param2$sd2)

  ## Fill out distance matrix
  dist_cs <- matrix(0, ncol = numclust, nrow = numclust)
  for(iclust_1 in 1:numclust){
    for(iclust_2 in 1:numclust){
      dist_cs[iclust_2, iclust_1] <-
        one_symmetric_kl(mu1 = mn_model1[iclust_1], mu2 = mn_model2[iclust_2],
                         sd1 = sd_model1[iclust_1], sd2 = sd_model2[iclust_2])
    }
  }
  rownames(dist_cs) <- rep("C1", numclust)
  colnames(dist_cs) <- rep("C2", numclust)
  return(dist_cs)
}


#' Apply a gmm in each 1-dimensional cytogram.
#' 
#' @param one_y One-column matrix.
#' @param numclust Number of clusters.
#' @return 
#' @export
gmm_each <- function(one_y, numclust){
  
  ## Basic check
  stopifnot(ncol(one_y) == 1)

  ## Do Gaussian Mixture model
  ## obj <- mclust::Mclust(data = one_y, G = numclust,
##                             modelNames = "V", verbose = FALSE)
  obj <- my_mclust(one_y, numclust, FALSE)

  ## Memberships (soft- and hard-clustered)
  hard_mem = obj$z  %>% apply(1, which.max)
  soft_mem = obj$z  %>%
    apply(1, function(myrow){
      sample(1:2, size = 1, replace = FALSE, prob=myrow)
    })
  tab <- tibble(y = as.numeric(one_y),
                soft_cluster = factor(soft_mem, levels = c(1,2)),
                hard_cluster = factor(hard_mem, levels = c(1,2)))

  ## parameter table
  mn1 = obj$parameters$mean[[1]]
  mn2 = obj$parameters$mean[[2]]
  sds = obj %>% .$parameters %>% .$variance %>% .$sigmasq %>% sqrt()
  sd1 = sds[1]
  sd2 = sds[2]
  prob1 = obj$parameters$pro[1]
  prob2 = obj$parameters$pro[2]

  ## ggplot(data.frame(x=as.numeric(one_y))) +
  ## geom_histogram(aes(x=x)) +
  ## geom_vline(xintercept = mn1, col = 'blue') +
  ## geom_vline(xintercept = mn1 + 2*sd1, col = 'skyblue') +
  ## geom_vline(xintercept = mn1 - 2*sd1, col = 'skyblue') +
  ## geom_vline(xintercept = mn2, col = 'red') +
  ## geom_vline(xintercept = mn2 - 2*sd2, col = 'orange') +
  ## geom_vline(xintercept = mn2 + 2*sd2, col = 'orange')
  param = tibble(mn1 = mn1,
                 mn2 = mn2,
                 sd1 = sd1,
                 sd2 = sd2,
                 prob1 = prob1,
                 prob2 = prob2)
  resp = obj$z

  return(list(tab = tab, param = param, resp = resp))##, sigma_list = sigma_list))
}
```


Here's a function for soft-gating given a 2-column responsibility matrix.

```{r,}
#' Soft-gates a responsibility matrix by a bernoulli (or multinoulli) draw.
#' 
#' @param oneresp A 2-column responsibility matrix
#' 
#' @return 
soft_gate_one_responsibility_matrix <- function(oneresp){

  ## Setup
  numclust = ncol(oneresp)
  vec = rep(0,numclust)

  ## Draw the 0-1 memberships
  zero_one_mat = apply(oneresp, 1, function(myrow){
    draw = sample(1:numclust, size=1, prob=myrow)
    vec[draw]= 1
    vec
  }) %>% t()

  ## Check dimensions and return
  stopifnot(all(dim(zero_one_mat) == dim(oneresp)))
  return(zero_one_mat)
}

```

The `many_mixtures()` function uses a few helpers: 

```{r} 
#' Apply flowmeans in each cytogram.
#' 
#' @param ylist Data.
#' @param numclust Number of clusters.
#' @return 
#' @export
flowmeans_each <- function(ylist, numclust){

  ## Basic check
  stopifnot(ncol(ylist[[1]])==1)

  ## Get cluster labels from the peaks
  fmns_obj <- flowMeans::flowMeans(x = ylist, NumC = numclust)
  labeled_ylist <- data.frame(cluster = fmns_obj@Label, ylist) %>% tibble::as_tibble()
  colnames(labeled_ylist)[2] = "Y"
  
  ## Calculate cluster parameters
  cluster_params <- labeled_ylist %>% group_by(cluster) %>% 
    summarise(mu = mean(Y),
              prob = n()/nrow(labeled_ylist), 
              sigma = ifelse(!is.na(var(Y)), var(Y), 1e-10))
  return(list(fmns_obj = fmns_obj, cluster_params = cluster_params))
}
```

```{r}
#' Apply the hungarian matching algorithm to each time point.
#'
#' @param flowmeans_obj
#' 
#' @return
match_clusters <- function(fmns_obj){
  
  ## Initialize some objects
  TT <- length(fmns_obj)
  numc <- nrow(fmns_obj[[1]]$cluster_params)
  mu <- matrix(nrow = TT, ncol = numc)
  sigma <- matrix(nrow = TT, ncol = numc)
  prob <- matrix(nrow = TT, ncol = numc)
  costs <- rep(NA, TT)
  memlist <- list(fmns_obj[[1]]$fmns_obj@Label)
  
  ## First row is spoken for
  mu[1,] <- fmns_obj[[1]]$cluster_params$mu
  sigma[1,] <- fmns_obj[[1]]$cluster_params$sigma
  prob[1,] <- fmns_obj[[1]]$cluster_params$prob
  
  ## Fill in the rest of the rows by sequentially matching clusters from t-1 to
  ## t, using the Hungarian Algorithm
  for(tt in 2:TT){
    dt_to_tp1 <- my_symmetric_kl(c1 = fmns_obj[[tt-1]]$cluster_params,
                                 c2 = fmns_obj[[tt]]$cluster_params)
    hng_tt <- RcppHungarian::HungarianSolver(dt_to_tp1)
    hng_order <- hng_tt$pairs %>% data.frame() %>% arrange(.[,2]) %>% .[,1]

    fmns_obj[[tt]]$cluster_params <- fmns_obj[[tt]]$cluster_params[hng_order,]
    mu[tt,] <- fmns_obj[[tt]]$cluster_params$mu
    prob[tt,] <- fmns_obj[[tt]]$cluster_params$prob
    sigma[tt,] <- fmns_obj[[tt]]$cluster_params$sigma[hng_order]
    costs[tt] <- hng_tt$cost
    if(mean(abs(mu[tt,] - mu[tt-1,]))/max(abs(mu[tt,])) > 1){
      cat(paste("Bad Match at time", tt, "\n"))
    }

    ## Convert labels
    label.convert <- function(c1){hng_tt$pairs[c1,2]}
    memlist[[tt]] <- sapply(fmns_obj[[tt]]$fmns_obj@Label, label.convert)
  }
  
  return(list(mu = mu, prob = prob, sigma = sigma, costs = costs, memlist = memlist))
}

#' Given two K x 2 columns with parameters, make K x K distance matrix.
#' 
#' @param c1 Data frame with K rows and 2 columns (mu and sigma)
#' @param c2 Another data frame of the same size as \code{c1}.
#'
#' @return K x K matrix.
my_symmetric_kl <- function(c1, c2){
  
  ## Make sure were using the same number of clusters
  assertthat::assert_that(nrow(c1) == nrow(c2))
  numclust <- nrow(c1)

  ## Fill out distance matrix
  dist_cs <- matrix(0, ncol = numclust, nrow = numclust)
  for(iclust_1 in 1:numclust){
    for(iclust_2 in 1:numclust){
      dist_cs[iclust_2, iclust_1] <-
        one_symmetric_kl(mu1 = c1$mu[iclust_1],
                         mu2 = c2$mu[iclust_2], 
                         sd1 = sqrt(c1$sigma[iclust_1]),
                         sd2 = sqrt(c2$sigma[iclust_2]))
    }
  }
  rownames(dist_cs) <- rep("C1", numclust)
  colnames(dist_cs) <- rep("C2", numclust)
  return(dist_cs)
}

#' Symmetric KL divergence between two Gaussian distributions.
#' @param mu1 Mean for distribution 1.
#' @param mu2 Mean for distribution 2.
#' @param sd1 Standard deviation for distribution 1.
#' @param sd2 Standard deviation for distribution 2.
one_symmetric_kl <- function(mu1, mu2, sd1, sd2){
  stopifnot(length(mu1)==1 & length(mu2) == 1 &
            length(sd1) == 1 & length(sd2) == 1)
  kl12 <- log(sd2/sd1) + (sd1^2 + (mu1 - mu2)^2)/(2*sd2^2) - 1/2
  kl21 <- log(sd1/sd2) + (sd2^2 + (mu2 - mu1)^2)/(2*sd1^2) - 1/2
  kl_sym <- 0.5*(kl12 + kl21)
  return(kl_sym)
}
```


Here's a useful function to create a flowtrend-like object but containing the
"oracle" information about the cluster means, variances, and mixture
probabilities.

```{r}
#' Reformatting |datobj| to create a flowtrend-like object that contains
#' "oracle" information of the model that
#' generates the simulated pseudo-real data.
#'
#' @param datobj A data object.
#'
#' @return A flowtrend-like object containing mn, sigma, and prob.
#'
#' @export
create_oracle <- function(datobj){

  TT = nrow(datobj$mns)
  dimdat = 1
  numclust = ncol(datobj$mns)

  ## Make a fake object in a similar format as a |flowtrend| object
  fake_obj = list()
  fake_obj$mn = array(NA, dim = c(TT, dimdat,numclust))
  fake_obj$mn[,1,] = datobj$mns
  fake_obj$prob = datobj$prob
  fake_obj$sigma = array(NA, dim = c(numclust, dimdat, dimdat))
  fake_obj$sigma[1,1,1] = datobj$sd1^2
  fake_obj$sigma[2,1,1] = datobj$sd2^2
  fake_obj$numclust = numclust
  return(fake_obj)
}
```




## Example using other cluster algorithms 

We will see some examples of how to use `underfit_flowmeans()` and `overfit_flowmeans()`.

```{r, eval = FALSE, fig.width = 8, fig.height = 8}
## Generate data
numclust = 3
TT = 100
dimdat = 1
set.seed(0)
dt = gendat_1d(TT = TT, ntlist = rep(TT, 100))
ylist = dt %>% dt2ylist()
truth = gendat_1d(TT = TT, ntlist = rep(TT, 100), return_model=TRUE)

## Fit the two methods
obj_underfit = underfit_flowmeans(ylist = ylist, numclust = 3)
obj_overfit = overfit_flowmeans(ylist = ylist, numclust = 3)

## Make the mean plots
o = obj_underfit$mu %>% colMeans() %>% order()
obj_underfit = reorder_flowmeans(obj_underfit, o)
g1 = plot_1d_flowmeans(reorder_flowmeans(obj_underfit, o), ylist) +
  geom_line(aes(x=time, y=mean, group = cluster), data = truth,  col = 'black')

o = obj_overfit$mu %>% colMeans() %>% order()
obj_overfit = reorder_flowmeans(obj_overfit, o)
g2 = plot_1d_flowmeans(obj_overfit, ylist) +
  geom_line(aes(x=time, y=mean, group = cluster), data = truth, col = 'black')

do.call(ggpubr::ggarrange, c(list(g1, g2), ncol=1, nrow=2))

## Make the probability plots
g1 = obj_overfit$prob %>% my_wrangle("prob") %>%
  ggplot() +
    geom_line(aes(x=time, y = prob, group = cluster, col = cluster), size = rel(1)) +
  ggtitle("Estimated cluster probability") +
  geom_line(aes(x=time, y=prob, group = cluster), data = truth, col = 'black')

g2 = obj_underfit$prob %>% my_wrangle("prob") %>%
  ggplot() +
    geom_line(aes(x=time, y = prob, group = cluster, col = cluster), size = rel(1)) +
    ggtitle("Estimated cluster probability") +
  geom_line(aes(x=time, y=prob, group = cluster), data = truth, col = 'black')

do.call(ggpubr::ggarrange, c(list(g1, g2), ncol=1, nrow=2))
```


## Oracle

A flowtrend-like object that contains "oracle" information of the model that
generates the simulated pseudo-real data.

```{r}

#' Reformatting |datobj| to create a flowtrend-like object that contains "oracle" information of the model that
#' generates the simulated pseudo-real data.
#' 
#' @param datobj A data object.
#'
#' @return A flowtrend-like object containing mn, sigma, and prob.
#'
#' @export
create_oracle <- function(datobj){
  TT = nrow(datobj$mns)
  dimdat = 1
  numclust = ncol(datobj$mns)
  fake_obj = list()

  fake_obj$mn = array(NA, dim = c(TT,dimdat,numclust))
  fake_obj$mn[,1,] = datobj$mns
  fake_obj$prob = datobj$prob
  fake_obj$sigma = array(NA, dim = c(numclust, dimdat, dimdat))
  fake_obj$sigma[1,1,1] = datobj$sd1^2
  fake_obj$sigma[2,1,1] = datobj$sd2^2
  fake_obj$numclust = numclust
  return(fake_obj)
}
```


## Evaluating performance: soft RAND index

We will use a "soft" Rand index that replaces the regular Rand index:

$$ \sum_{i, i'} 1\{ \hat C_i = \hat C_{i'}, C_i^* \neq C_{i'}^*\}.$$

which measures, for every pair of points $i$ and $i'$, the number of times that
the two clustering mechanisms *disagree*.

Now, let's say that the two mechanisms give *probabilities*:

$$\hat \gamma_{ik} = \hat P(\hat C_i = k),$$
$$\hat \gamma^*_{ik} = \hat P(\hat C_i^* = k).$$

Then, the probability that the clustering is the same $P(C_i^* = C_{i'}^*)$ for
the pair of points $i$ and $i'$ is:

$$ (\gamma_i^*)^T (\gamma_{i'}^*) = \sum_{k=1} P(C_i = k) P(C_i^* = k) = P(C_i^* = C_{i'}^*).$$

and the probaility they are different is:

$$ (\gamma_i^*)^T (\gamma_{i'}^*) = \sum_{k=1} P(C_i = k) P(C_i^* = k) = P(C_i^* = C_{i'}^*).$$

So, we can measure the difference as:

$$\sum_{i,i'} (\hat \gamma_i^T \hat \gamma_{i'})\cdot(1-  \gamma^*_i^T \gamma^*_{i'}) $$

And when one of the clusterings is soft, we can still use a 0-1 vector as $\gamma$.

```{r soft-rand}
#' A "soft" version of a rand index between two sets of responsibility
#' (membership probability) matrices. Measures the /disagreement/ between the two clusterings.
#' 
#' @param resp_list1 One list of responsibility matrices.
#' @param resp_list2 Another list of responsibility matrices.
#' @param times Optional; if you would like to isolate your attention to some specific times.
#'
#' @return A single soft rand index number
#' @export
rand_old <- function(resp_list1, resp_list2, times = NULL, prop = .25){

  if(!is.null(times)) resp_list1 = resp_list1[times]
  if(!is.null(times)) resp_list2 = resp_list2[times]

  rand_onetime <- function(resp1, resp2){
    stopifnot(nrow(resp1) == nrow(resp2))
    stopifnot(ncol(resp1) == ncol(resp2))
    nt = nrow(resp1)
    
    ## Form the score
    mat11 = resp1 %*% t(resp1)
    mat22 = resp2 %*% t(resp2)
    mat11not = (1-mat11)
    mat22not = (1-mat22)

    ## Make the diagonals not matter anywhere
    diag(mat11) = 0
    diag(mat22) = 0
    diag(mat11not) = 0
    diag(mat22not) = 0

    a = mat11 * mat22
    b = mat11not * mat22not
    c = mat11 * mat22not
    d = mat11not * mat22

    return(c(a = sum(a), b = sum(b), c = sum(c), d = sum(d)))
  }
  abcd_over_time = mapply(rand_onetime, resp_list1, resp_list2)
  abcdmat = abcd_over_time %>% t()
  abcd = abcdmat %>% colSums()
  score = (abcd["a"] + abcd["b"])/  (sum(abcd))
  return(score)
}

#' Rand index between responsibilities.
#'
#' @param resp_list1 One list.
#' @param resp_list2 Another list.
#' @param times A subset of the time points (out of 1:length(resp_list1)) to
#'   examine.
#' @param smaller If TRUE, use only a small (sampled) subset of the particles'
#'   responsibilities for calculating RAND.
#' @param prop How much to downsample; defaults to 0.1.
#' @export
rand <- function(resp_list1, resp_list2, times = NULL, smaller = TRUE, prop = 0.1){
 
  ## Basic checks
  stopifnot(all(sapply(resp_list1, nrow) == sapply(resp_list2, nrow)))

  ## Subset the times if needed
  if(!is.null(times)) resp_list1 = resp_list1[times]
  if(!is.null(times)) resp_list2 = resp_list2[times]

  ## names(everything)
  ## list2env(everything,envir = environment())
  ## resp_list1 = resp_oracle
  ## resp_list2 = true_resp
  if(smaller){
    indslist = lapply(resp_list1, function(oneresp){
      inds = sample(x=1:nrow(oneresp), size=ceiling(nrow(oneresp)*prop), replace=FALSE) %>% sort()
    })
    resp_list1 = mapply(function(a,b)a[b,,drop=FALSE], resp_list1, indslist, SIMPLIFY=FALSE)
    resp_list2 = mapply(function(a,b)a[b,,drop=FALSE], resp_list2, indslist, SIMPLIFY=FALSE)
  }

  ## Make each list into one long matrix
  resp1 = Reduce(rbind, resp_list1)
  resp2 = Reduce(rbind, resp_list2)
  ## resp1 = do.call(rbind, resp_list1)## %>% bind_rows()
  ## resp2 = do.call(rbind, resp_list2)## %>% bind_rows()
  
  stopifnot(nrow(resp1) == nrow(resp2))
  stopifnot(ncol(resp1) == ncol(resp2))
  nt = nrow(resp1)
  
  ## Form the score
  mat11 = resp1 %*% t(resp1)
  mat22 = resp2 %*% t(resp2)
  mat11not = (1-mat11)
  mat22not = (1-mat22)

  ## Make the diagonals not matter anywhere
  diag(mat11) = 0
  diag(mat22) = 0
  diag(mat11not) = 0
  diag(mat22not) = 0

  a = mat11 * mat22
  b = mat11not * mat22not
  c = mat11 * mat22not
  d = mat11not * mat22

  abcd = c(a = sum(a), b = sum(b), c = sum(c), d = sum(d))
  score = (abcd["a"] + abcd["b"])/  (sum(abcd))
  return(score)
}



#' 2 x 2 contigency table from membership vectors.
#' 
#' @param mem1 Membership vector.
#' @param mem2 Another membership vector.
#'
#' @return A 3x3 matrix containing (1) a 2 x 2 table in the first [1:2,1:2]
#'   entries, and (2) row sums and column sums and total sums in the [,3], [3,]
#'   entries.
#' @export
make_contingency_table<-function(mem1, mem2){
  tab = table(mem1, mem2)
  tab = cbind(tab, rowSums(tab))
  tab = rbind(tab, colSums(tab))
  return(tab)
}


#' RAND index.
#' 
#' @param tab  A matrix containing  a 2 x 2 table in the first [1:2,1:2]
#'   entries; e.g., from make_contingency_table().
#'
#' @return Rand index.
#' @export
get_rand_from_table <- function(tab){
  numer = sum(sapply(as.numeric(tab), function(nij) choose(nij, 2))) +
    tab[1,1] * tab[2,2] + tab[1,2] * tab[2,1]
  denom = (choose(sum(tab), 2))
  ri = numer/denom
  return(ri)
}


#' Faster rand index calculation from membership vectors.
#'
#' @param mem1
#' @param mem2 
#' 
#' @return RAND index.
#' @export
rand_from_mems <- function(mem1, mem2){
  make_contingency_table(mem1, mem2) %>%
    .[1:2,1:2] %>%
    get_rand_from_table()
}
```

```{r soft-adjusted-rand}
#' A "soft" *and adjusted* version of a rand index between two lists of responsibility
#' (membership probability) matrices. Measures the /disagreement/ between the two clusterings.
#' 
#' @param resp_list1 One list of responsibility matrices.
#' @param resp_list2 Another list of responsibility matrices.
#' @param times Optional; if you would like to isolate your attention to some
#'   specific times.
#'
#' @return A single soft rand index for all particles across all times.
#' 
#' @export
adjusted_rand <- function(resp_list1, resp_list2, times = NULL){ 

  ## Basic checks
  if(!is.null(times)) resp_list1 = resp_list1[times]
  if(!is.null(times)) resp_list2 = resp_list2[times]
  
  all_mat_over_time = mapply(adjusted_rand_onetime, resp_list1, resp_list2,
                             SIMPLIFY = FALSE)
  mat = Reduce('+', all_mat_over_time)

  n = sum(mat)
  sum_a = sum(sapply(rowSums(mat), choose, 2))
  sum_b = sum(sapply(colSums(mat), choose, 2))
  numer = sum(sapply(mat, function(a) choose(a,2))) -
    sum_a * sum_b / choose(n, 2)
  denom = (sum_a + sum_b)/2 - (sum_a * sum_b)/choose(n,2) 
  ari = numer/denom
  return(ari)
}


#' A "soft" *and adjusted* version of a rand index between two responsibility
#' (membership probability) matrices. Measures the /disagreement/ between the
#' two clusterings.
#' 
#' @param resp1 One responsibility matrices.
#' @param resp2 Another responsibility matrices.
#'
#' @return A single soft rand index for all particles.
#' @export
adjusted_rand_onetime <- function(resp1, resp2){

  ## Basic checks
  stopifnot(nrow(resp1) == nrow(resp2))
  stopifnot(ncol(resp1) == ncol(resp2))
  nt = nrow(resp1)
  
  ## Next, build contingency table
  mem1 = resp1 %>% apply(1, function(a){(1:2)[which(a==0)]}) ## why is this a==0?? TODO address this.
  mem2 = resp2 %>% apply(1, function(a){(1:2)[which(a==0)]})
  mat = matrix(NA, nrow=2, ncol=2)
  mat[1,1] = sum(mem1==1 & mem2 == 1) 
  mat[2,2] = sum(mem1==2 & mem2 == 2) 
  mat[1,2] = sum(mem1==1 & mem2 == 2) 
  mat[2,1] = sum(mem1==2 & mem2 == 1) 
  return(mat)
}
```


```{r try-soft-rand, eval = FALSE}
numclust = 3
TT = 100
dimdat = 1
set.seed(0)
dt = gendat_1d(TT = TT, ntlist = rep(TT, 100))
ylist = dt %>% dt2ylist()
truth = gendat_1d(TT = TT, ntlist = rep(TT, 100), return_model=TRUE)
res = flowtrend(ylist=ylist, numclust=3, l=2, l_prob=1, lambda = .01,
                lambda_prob=0.01, verbose=TRUE, nrestart=1)
res2 = flowtrend(ylist=ylist, numclust=3, l=2, l_prob=1, lambda = 1,
                 lambda_prob=1, verbose=TRUE, nrestart=1)

## Calculate the soft rand index of two different models
rand(res$resp, res2$resp)
rand(res$resp, res$resp)
rand(res2$resp, res2$resp)

g1 = plot_1d(ylist=ylist, obj=res2)
g2 = plot_1d(ylist=ylist, obj=res)
do.call(ggpubr::ggarrange, c(list(g1, g2), ncol=1, nrow=2))

## Case 1: above

## Case 2: one is the TRUTH; based on the

## Case 3: one is a hard clustering. 
plot(ylist[[1]], col = obj$memlist[[1]])
obj$resp = get_resp_from_labels(obj$memlist)
rand(res$resp, res2$resp)
rand(res$resp, res$resp)

## Next, code up the truth
a = dt %>% group_by(time ) %>% group_split() %>%
  lapply(function(one_dt) one_dt %>% pull(cluster))


#' Helper to get, from labels
get_resp_from_labels <- function(labels){
  numclust = max(labels[[1]])
  lapply(labels, function(one_time_label){
  one_resp = rep(0,3)
  resp = sapply(obj$memlist[[1]], function(ii){
    one_resp[ii] = 1
    return(one_resp)
  }) %>% t()
  return(resp)
  })
}
```


It's also helpful to have a function that takes a list of discrete memberships
(integers 1,..,K) and convert it to a list of responsibility matrices similar in
format to `obj$resp` of a flowtrend object `obj`.

```{r}
#' Convert list of memberships into a list of responsibilities.
#' 
#' @param memlist List of memberships
#'
#' @return
#' @export
memlist_to_respmat <- function(memlist){
  numclust = max(sapply(memlist, max))
  respmats = lapply(memlist, function(mem){
    respmat = lapply(mem, function(onemem){
      onerow = rep(0, numclust)##c(0,0)
      onerow[onemem] = 1
      return(onerow)
    }) %>% do.call(rbind, .)
    return(respmat)
  })
  return(respmats)
}
```


## Generating "pseudo-real" data 

Two clusters will be taken from an estimated _flowtrend_ model fit on real data,
downloaded from here: 

https://zenodo.org/records/6471995

to [./data](./data).

```{r}
## This data is from the results from 
here::i_am("7simulations.Rmd")
datadir = file.path(here::here(), "inst", "data")
res = readRDS(file.path(datadir, "1d-cvres.rds")) %>% .$bestres

## Picoeuk
iclust = 3
mn1 = cbind(1, res$X) %*% res$beta[[iclust]] %>% as.numeric()

## Prochlorococcus
iclust = 4
mn2 = cbind(1, res$X) %*% res$beta[[iclust]] %>% as.numeric()

## Cluster probabilities
probs = res$pie[,c(3, 4)]  
probs = probs / rowSums(probs)

## Save them as separte objects
mns_orig = cbind(mn1, mn2)
probs_orig = probs
```

Let's smooth these using a trend-filter;

+ The cluster means will be taken to directly trend filtered at 2. 
+ The log odds will be smoothed. 

Specifically, recall that $p = e^\gamma / (1 + e^\gamma)$.  So, we will take
$\gamma = \log(p/(1-p)) \propto \log(p)$, smooth it, and recreate $p$.


Next, generate new 1d data.


```{r generate-data, eval = FALSE, echo = TRUE}
nt = 1000
sd1 = res$sigma %>% .[,1,1] %>% .[3] %>% sqrt() 
sd2 = res$sigma %>% .[,1,1] %>% .[4] %>% sqrt()

## Smooth means
mn1 = mns_orig[,1]
mn2 = mns_orig[,2]
gap = mean(mn1) - mean(mn2)
mn1 = mn1 - gap
mn1 = mn1 %>% fit_tf(ord = 2)
mn2 = mn2 %>% fit_tf(ord = 2)

## Smooth probabilities
probs = probs_orig
gamma = log(probs[,1]/probs[,2])
gamma = gamma %>% fit_tf(ord = 1)
probs[,1] = gamma %>% exp()
probs[,1] = probs[,1]/(1 + probs[,1])
probs[,2] =  1 - probs[,1] 

## Create all the data
for(isignal in 0:12){
  print("isignal")
  print(isignal)
  parallel::mclapply(1:10, function(isim){
    printprogress(isim, 10)
  ## for(isim in 1:10){
    mns = cbind(mn1 + isignal * 0.05, mn2)
    set.seed(10000 + isignal * 100 + isim)
    datobj = pseudoreal_gendat_1d(mns, probs, sd1, sd2, nt = 1000)
    datobj[["mns"]] = mns
    datobj[["probs"]] = probs
    datobj[["sd1"]] = sd1
    datobj[["sd2"]] = sd2
    destin = file.path("~/repos/flowtrend/inst/output/1dsim-pseudoreal",
                       paste0("isignal-", isignal),
                       paste0("isim-", isim))
    create_destin(destin)
    ## if(file.exists(file.path(destin, "datobj.RDS"))) next
    saveRDS(datobj, file = file.path(destin, "datobj.RDS"))
  ## }
  }, mc.cores = 8)
  cat(fill=TRUE)
}
```

## Miscellaneous helpers

Lastly, there are some miscellaneous helpers that are useful when running actual
jobs on a server.


The first one is `create_destin()`, which creates a directory if it doesn't already exist.

```{r}
#' Creates a directory \code{destin}, if it doesn't already exist.
#'
#' @param destin Destination directory.
#'
#' @return Nothing.
#' @export
create_destin <- function(destin){
  if(!dir.exists(destin)){
    dir.create(destin, recursive = TRUE)
    cat("Creating destin: ", destin, fill=TRUE)
  } else {
    cat("All output goes out to destin: ", destin, fill = TRUE)
  }
}
```


Another helper `parse_args()` helps R read in trailing arguments from the command line, like this:

`parse_args(args = commandArgs(trailingOnly = TRUE), verbose=TRUE)`

so that one can run jobs using a SLURM command such as:

`sbatch --export=summ=0 --array=1 run-3dreal.slurm`

from which the R script can access the `summ=0` variable.


```{r}
#' Parse command line arguments and assigns the values of them. |args| is meant
#' to just be additional command line arguments.
#'
#' @param args Argument.
#'
#' @return Nothing.
#' @export
parse_args <- function(args, verbose=FALSE){
  args = sapply(args, strsplit, "=")
  print(args)
  for(arg in args){

    ## Check if the thing is integer
    all_numbers = str_detect(arg[2], "^[:digit:]+$")

    ## Assign the variable
    if(all_numbers){
      assign(arg[1], as.numeric(arg[2]), inherits = TRUE)
    } else {
      assign(arg[1], arg[2], inherits = TRUE)
    }

    if(verbose){
      cat(arg[1], "takes the value of", arg[2],
          "from command line input", fill=TRUE)
    }
    print("===============================")
  }
}


```






# Documenting the package and building

We finish by running commands that will document, build, and install the
package.  It may also be a good idea to check the package from within this file.

```{r, results='hide'}
litr::document() # <-- use instead of devtools::document() 
```


